{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Series-Library already installed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Check if \"Time-Series-Library\" directory exists. \n",
    "# If so, we assume Time-Series-Library repository is already installed properly. \n",
    "if os.path.isdir(\"Time-Series-Library\"):\n",
    "    print(\"Time-Series-Library already installed\")\n",
    "else:\n",
    "    # Clone the repository of Time-Series-Library into the project directory. \n",
    "    print(\"Downloading Time-Series-Library repository...\")\n",
    "    !git clone https://github.com/thuml/Time-Series-Library.git\n",
    "    \n",
    "    print(\"Installing required packages for Time-Series-Library...\")\n",
    "    !pip install -r Time-Series-Library/requirements.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages for TABE\n",
      "Requirement already satisfied: yfinance in /Users/cloudj/opt/anaconda3/envs/tscookbook/lib/python3.9/site-packages (from -r ./requirements.txt (line 1)) (0.2.51)\n",
      "Requirement already satisfied: pandas in /Users/cloudj/opt/anaconda3/envs/tscookbook/lib/python3.9/site-packages (from -r ./requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/cloudj/opt/anaconda3/envs/tscookbook/lib/python3.9/site-packages (from -r ./requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /Users/cloudj/opt/anaconda3/envs/tscookbook/lib/python3.9/site-packages (from -r ./requirements.txt (line 4)) (3.7.0)\n",
      "Requirement already satisfied: torch in /Users/cloudj/opt/anaconda3/envs/tscookbook/lib/python3.9/site-packages (from -r ./requirements.txt (line 5)) (2.0.0)\n",
      "Collecting pyro\n",
      "  Using cached Pyro-3.16.tar.gz (298 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[7 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/vy/swc92n890xq1d7g08y98sqwr0000gn/T/pip-install-6yi2o7e6/pyro_35f452a9aa324b17887f737241b4bcd1/setup.py\", line 23\n",
      "  \u001b[31m   \u001b[0m     exec code in constants\n",
      "  \u001b[31m   \u001b[0m          ^\n",
      "  \u001b[31m   \u001b[0m SyntaxError: Missing parentheses in call to 'exec'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing required packages for TABE\")\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add Time-Series-Library directory to module lookup paths\n",
    "sys.path.append('Time-Series-Library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n",
      "RSS Mem Usage: cur=357.34 incr=0.00 acc_incr=0.00 MB\n",
      "Python Mem Usage: cur=0.01 incr=0.00 acc_incr=0.00 peak=0.01 MB\n",
      "\n",
      "Configurations =================================\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           TABE_v0.2           Model:              TABE                \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               TABE                Root Path:          ./                  \n",
      "  Data Path:          dataset_BTC_r25.csv Features:           MS                  \n",
      "  Target:             OT                  Freq:               d                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            32                  Label Len:          32                  \n",
      "  Pred Len:           1                   Seasonal Patterns:  Monthly             \n",
      "  Inverse:            1                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             1                   Dec In:             1                   \n",
      "  C Out:              1                   d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       1                   Batch Size:         10                  \n",
      "  Patience:           3                   Learning Rate:      0.001               \n",
      "  Des:                'Exp'               Loss:               'MSE'               \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: mps\n",
      "Use GPU: mps\n",
      "Use GPU: mps\n",
      "\n",
      "Training base models ==================================\n",
      "\n",
      "Training ETS ...\n",
      "\n",
      "Training SARIMA ...\n",
      "\n",
      "Training iTransformer ...\n",
      "base_train 174\n",
      "val 26\n",
      "Epoch: 1 cost time: 55.32770276069641\n",
      "Epoch: 1, Steps: 18 | Train Loss: 0.4326469 Vali Loss: 0.2005022\n",
      "Validation loss decreased (inf --> 0.200502).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "RSS Mem Usage: cur=280.34 incr=-77.00 acc_incr=-77.00 MB\n",
      "Python Mem Usage: cur=1.21 incr=1.20 acc_incr=1.20 peak=1.32 MB\n",
      "\n",
      "Training combiner model ======================\n",
      "ensemble_train 29\n",
      "Epoch: 1 | Train Loss: 0.0288245 Vali Loss: 0.2535455\n",
      "Validation loss decreased (inf --> 0.253545).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.19495415687561\n",
      "RSS Mem Usage: cur=217.86 incr=-62.48 acc_incr=-139.48 MB\n",
      "Python Mem Usage: cur=1.69 incr=0.48 acc_incr=1.68 peak=1.88 MB\n",
      "Epoch: 1 | Train Loss: 0.2007224 Vali Loss: 0.4014831\n",
      "Validation loss decreased (inf --> 0.401483).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.197875261306763\n",
      "RSS Mem Usage: cur=242.48 incr=24.62 acc_incr=-114.86 MB\n",
      "Python Mem Usage: cur=1.71 incr=0.02 acc_incr=1.70 peak=1.94 MB\n",
      "Epoch: 1 | Train Loss: 0.0790020 Vali Loss: 0.1765380\n",
      "Validation loss decreased (inf --> 0.176538).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.284598112106323\n",
      "RSS Mem Usage: cur=253.92 incr=11.44 acc_incr=-103.42 MB\n",
      "Python Mem Usage: cur=1.73 incr=0.02 acc_incr=1.72 peak=1.97 MB\n",
      "Epoch: 1 | Train Loss: 1.7988484 Vali Loss: 0.7215562\n",
      "Validation loss decreased (inf --> 0.721556).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.05774188041687\n",
      "RSS Mem Usage: cur=248.94 incr=-4.98 acc_incr=-108.41 MB\n",
      "Python Mem Usage: cur=1.74 incr=0.01 acc_incr=1.73 peak=1.98 MB\n",
      "Epoch: 1 | Train Loss: 0.1298668 Vali Loss: 1.5351814\n",
      "Validation loss decreased (inf --> 1.535181).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.11049509048462\n",
      "RSS Mem Usage: cur=248.53 incr=-0.41 acc_incr=-108.81 MB\n",
      "Python Mem Usage: cur=1.73 incr=-0.01 acc_incr=1.72 peak=1.98 MB\n",
      "Epoch: 1 | Train Loss: 2.3652422 Vali Loss: 1.9051186\n",
      "Validation loss decreased (inf --> 1.905119).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.213757276535034\n",
      "RSS Mem Usage: cur=271.98 incr=23.45 acc_incr=-85.36 MB\n",
      "Python Mem Usage: cur=1.73 incr=0.01 acc_incr=1.73 peak=1.98 MB\n",
      "Epoch: 1 | Train Loss: 0.1452633 Vali Loss: 1.1511027\n",
      "Validation loss decreased (inf --> 1.151103).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.14422607421875\n",
      "RSS Mem Usage: cur=272.14 incr=0.16 acc_incr=-85.20 MB\n",
      "Python Mem Usage: cur=1.74 incr=0.01 acc_incr=1.73 peak=1.98 MB\n",
      "Epoch: 1 | Train Loss: 0.5225393 Vali Loss: 0.9936526\n",
      "Validation loss decreased (inf --> 0.993653).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.16825795173645\n",
      "RSS Mem Usage: cur=276.52 incr=4.38 acc_incr=-80.83 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.01 acc_incr=1.74 peak=1.99 MB\n",
      "Epoch: 1 | Train Loss: 1.8379251 Vali Loss: 0.5378596\n",
      "Validation loss decreased (inf --> 0.537860).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.194635152816772\n",
      "RSS Mem Usage: cur=244.25 incr=-32.27 acc_incr=-113.09 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.01 acc_incr=1.75 peak=1.99 MB\n",
      "Epoch: 1 | Train Loss: 0.0009756 Vali Loss: 0.8487976\n",
      "Validation loss decreased (inf --> 0.848798).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.093369722366333\n",
      "RSS Mem Usage: cur=253.70 incr=9.45 acc_incr=-103.64 MB\n",
      "Python Mem Usage: cur=1.74 incr=-0.02 acc_incr=1.73 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 2.2606356 Vali Loss: 0.1464527\n",
      "Validation loss decreased (inf --> 0.146453).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.14974808692932\n",
      "RSS Mem Usage: cur=245.17 incr=-8.53 acc_incr=-112.17 MB\n",
      "Python Mem Usage: cur=1.74 incr=0.00 acc_incr=1.73 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 1.1234280 Vali Loss: 0.3767459\n",
      "Validation loss decreased (inf --> 0.376746).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.10487198829651\n",
      "RSS Mem Usage: cur=257.31 incr=12.14 acc_incr=-100.03 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.00 acc_incr=1.74 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 0.3537663 Vali Loss: 0.2857151\n",
      "Validation loss decreased (inf --> 0.285715).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.175708770751953\n",
      "RSS Mem Usage: cur=253.52 incr=-3.80 acc_incr=-103.83 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.01 acc_incr=1.74 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 1.0032232 Vali Loss: 0.5123770\n",
      "Validation loss decreased (inf --> 0.512377).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.08674693107605\n",
      "RSS Mem Usage: cur=236.59 incr=-16.92 acc_incr=-120.75 MB\n",
      "Python Mem Usage: cur=1.76 incr=0.00 acc_incr=1.75 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 0.3848399 Vali Loss: 0.2553413\n",
      "Validation loss decreased (inf --> 0.255341).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.13463306427002\n",
      "RSS Mem Usage: cur=203.23 incr=-33.36 acc_incr=-154.11 MB\n",
      "Python Mem Usage: cur=1.76 incr=0.01 acc_incr=1.76 peak=2.00 MB\n",
      "Epoch: 1 | Train Loss: 1.4398811 Vali Loss: 0.4488416\n",
      "Validation loss decreased (inf --> 0.448842).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.252870082855225\n",
      "RSS Mem Usage: cur=242.12 incr=38.89 acc_incr=-115.22 MB\n",
      "Python Mem Usage: cur=1.74 incr=-0.02 acc_incr=1.73 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 0.2171974 Vali Loss: 0.3862461\n",
      "Validation loss decreased (inf --> 0.386246).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 18.96108913421631\n",
      "RSS Mem Usage: cur=201.44 incr=-40.69 acc_incr=-155.91 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.01 acc_incr=1.74 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 0.7330196 Vali Loss: 0.6259904\n",
      "Validation loss decreased (inf --> 0.625990).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.0927791595459\n",
      "RSS Mem Usage: cur=248.50 incr=47.06 acc_incr=-108.84 MB\n",
      "Python Mem Usage: cur=1.75 incr=0.01 acc_incr=1.74 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 2.9217303 Vali Loss: 0.3143495\n",
      "Validation loss decreased (inf --> 0.314350).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.1892569065094\n",
      "RSS Mem Usage: cur=225.77 incr=-22.73 acc_incr=-131.58 MB\n",
      "Python Mem Usage: cur=1.76 incr=0.01 acc_incr=1.75 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 0.3526973 Vali Loss: 0.3672752\n",
      "Validation loss decreased (inf --> 0.367275).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.10375714302063\n",
      "RSS Mem Usage: cur=246.44 incr=20.67 acc_incr=-110.91 MB\n",
      "Python Mem Usage: cur=1.76 incr=0.01 acc_incr=1.75 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 0.2740627 Vali Loss: 0.7707781\n",
      "Validation loss decreased (inf --> 0.770778).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.184783935546875\n",
      "RSS Mem Usage: cur=245.84 incr=-0.59 acc_incr=-111.50 MB\n",
      "Python Mem Usage: cur=1.77 incr=0.00 acc_incr=1.76 peak=2.01 MB\n",
      "Epoch: 1 | Train Loss: 2.8709099 Vali Loss: 0.4426090\n",
      "Validation loss decreased (inf --> 0.442609).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.270403146743774\n",
      "RSS Mem Usage: cur=245.62 incr=-0.22 acc_incr=-111.72 MB\n",
      "Python Mem Usage: cur=1.77 incr=0.01 acc_incr=1.77 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.2637599 Vali Loss: 0.3887461\n",
      "Validation loss decreased (inf --> 0.388746).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.172627210617065\n",
      "RSS Mem Usage: cur=243.14 incr=-2.48 acc_incr=-114.20 MB\n",
      "Python Mem Usage: cur=1.78 incr=0.01 acc_incr=1.77 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.2362800 Vali Loss: 0.2277352\n",
      "Validation loss decreased (inf --> 0.227735).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.171874046325684\n",
      "RSS Mem Usage: cur=245.00 incr=1.86 acc_incr=-112.34 MB\n",
      "Python Mem Usage: cur=1.75 incr=-0.03 acc_incr=1.74 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.4414456 Vali Loss: 0.1566318\n",
      "Validation loss decreased (inf --> 0.156632).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.034353971481323\n",
      "RSS Mem Usage: cur=244.30 incr=-0.70 acc_incr=-113.05 MB\n",
      "Python Mem Usage: cur=1.76 incr=0.01 acc_incr=1.75 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.0949262 Vali Loss: 0.1768346\n",
      "Validation loss decreased (inf --> 0.176835).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.13826322555542\n",
      "RSS Mem Usage: cur=243.00 incr=-1.30 acc_incr=-114.34 MB\n",
      "Python Mem Usage: cur=1.77 incr=0.01 acc_incr=1.76 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.1509856 Vali Loss: 0.1339473\n",
      "Validation loss decreased (inf --> 0.133947).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.160608768463135\n",
      "RSS Mem Usage: cur=244.69 incr=1.69 acc_incr=-112.66 MB\n",
      "Python Mem Usage: cur=1.77 incr=0.01 acc_incr=1.77 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 0.4012571 Vali Loss: 0.1584103\n",
      "Validation loss decreased (inf --> 0.158410).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.26081895828247\n",
      "RSS Mem Usage: cur=240.56 incr=-4.12 acc_incr=-116.78 MB\n",
      "Python Mem Usage: cur=1.78 incr=0.01 acc_incr=1.77 peak=2.02 MB\n",
      "Epoch: 1 | Train Loss: 1.3434129 Vali Loss: 0.5371028\n",
      "Validation loss decreased (inf --> 0.537103).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.068643808364868\n",
      "RSS Mem Usage: cur=241.59 incr=1.03 acc_incr=-115.75 MB\n",
      "Python Mem Usage: cur=1.79 incr=0.01 acc_incr=1.78 peak=2.03 MB\n",
      "CombinerModel.train() : 612.0290sec elapsed for getting predition data from base models\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.78trial/s, best loss: 2.1151644397430696]\n",
      "CombinerModel.train() : 1.9169sec elapsed for hyperparameter optimization\n",
      "\n",
      "Hyperparameters:\n",
      "   discount_factor  lookback_window_size  max_components  metric  \\\n",
      "0         1.471561                   1.0             3.0       0   \n",
      "\n",
      "   smoothing_factor  weighting_method  \n",
      "0          0.083851                 1  \n",
      "RSS Mem Usage: cur=275.14 incr=33.55 acc_incr=-82.20 MB\n",
      "Python Mem Usage: cur=2.58 incr=0.79 acc_incr=2.57 peak=2.83 MB\n",
      "\n",
      "Training adjuster model ======================\n",
      "Epoch: 1 | Train Loss: 0.0272013 Vali Loss: 0.8356435\n",
      "Validation loss decreased (inf --> 0.835644).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.15757393836975\n",
      "RSS Mem Usage: cur=189.39 incr=-85.75 acc_incr=-167.95 MB\n",
      "Python Mem Usage: cur=2.77 incr=0.20 acc_incr=2.77 peak=2.97 MB\n",
      "Epoch: 1 | Train Loss: 0.0041808 Vali Loss: 0.7435884\n",
      "Validation loss decreased (inf --> 0.743588).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.303516387939453\n",
      "RSS Mem Usage: cur=243.61 incr=54.22 acc_incr=-113.73 MB\n",
      "Python Mem Usage: cur=2.76 incr=-0.02 acc_incr=2.75 peak=3.02 MB\n",
      "Epoch: 1 | Train Loss: 0.0578121 Vali Loss: 0.8132012\n",
      "Validation loss decreased (inf --> 0.813201).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.09234094619751\n",
      "RSS Mem Usage: cur=244.77 incr=1.16 acc_incr=-112.58 MB\n",
      "Python Mem Usage: cur=2.78 incr=0.03 acc_incr=2.78 peak=3.02 MB\n",
      "Epoch: 1 | Train Loss: 1.4512515 Vali Loss: 0.7587497\n",
      "Validation loss decreased (inf --> 0.758750).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.18319272994995\n",
      "RSS Mem Usage: cur=247.50 incr=2.73 acc_incr=-109.84 MB\n",
      "Python Mem Usage: cur=2.79 incr=0.01 acc_incr=2.78 peak=3.03 MB\n",
      "Epoch: 1 | Train Loss: 0.7824873 Vali Loss: 1.0446545\n",
      "Validation loss decreased (inf --> 1.044654).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.068469047546387\n",
      "RSS Mem Usage: cur=218.41 incr=-29.09 acc_incr=-138.94 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.01 acc_incr=2.79 peak=3.04 MB\n",
      "Epoch: 1 | Train Loss: 0.0494782 Vali Loss: 0.7140543\n",
      "Validation loss decreased (inf --> 0.714054).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.145632028579712\n",
      "RSS Mem Usage: cur=244.61 incr=26.20 acc_incr=-112.73 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.79 peak=3.04 MB\n",
      "Epoch: 1 | Train Loss: 0.2721336 Vali Loss: 0.8983848\n",
      "Validation loss decreased (inf --> 0.898385).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.045753717422485\n",
      "RSS Mem Usage: cur=248.50 incr=3.89 acc_incr=-108.84 MB\n",
      "Python Mem Usage: cur=2.79 incr=-0.02 acc_incr=2.78 peak=3.05 MB\n",
      "Epoch: 1 | Train Loss: 0.0137632 Vali Loss: 1.1324620\n",
      "Validation loss decreased (inf --> 1.132462).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 18.993815898895264\n",
      "RSS Mem Usage: cur=223.56 incr=-24.94 acc_incr=-133.78 MB\n",
      "Python Mem Usage: cur=2.79 incr=0.01 acc_incr=2.78 peak=3.05 MB\n",
      "Epoch: 1 | Train Loss: 0.8252712 Vali Loss: 1.2245978\n",
      "Validation loss decreased (inf --> 1.224598).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.183521032333374\n",
      "RSS Mem Usage: cur=242.06 incr=18.50 acc_incr=-115.28 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.79 peak=3.05 MB\n",
      "Epoch: 1 | Train Loss: 0.0346849 Vali Loss: 1.5334908\n",
      "Validation loss decreased (inf --> 1.533491).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.037193775177002\n",
      "RSS Mem Usage: cur=245.08 incr=3.02 acc_incr=-112.27 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.01 acc_incr=2.80 peak=3.05 MB\n",
      "Epoch: 1 | Train Loss: 0.2635809 Vali Loss: 1.2646389\n",
      "Validation loss decreased (inf --> 1.264639).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.067776203155518\n",
      "RSS Mem Usage: cur=245.69 incr=0.61 acc_incr=-111.66 MB\n",
      "Python Mem Usage: cur=2.81 incr=0.01 acc_incr=2.80 peak=3.05 MB\n",
      "Epoch: 1 | Train Loss: 0.0018854 Vali Loss: 1.3407670\n",
      "Validation loss decreased (inf --> 1.340767).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.236093282699585\n",
      "RSS Mem Usage: cur=225.67 incr=-20.02 acc_incr=-131.67 MB\n",
      "Python Mem Usage: cur=2.81 incr=0.00 acc_incr=2.81 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.1028038 Vali Loss: 1.1949900\n",
      "Validation loss decreased (inf --> 1.194990).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.22598910331726\n",
      "RSS Mem Usage: cur=245.20 incr=19.53 acc_incr=-112.14 MB\n",
      "Python Mem Usage: cur=2.79 incr=-0.02 acc_incr=2.78 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.0000139 Vali Loss: 1.2499021\n",
      "Validation loss decreased (inf --> 1.249902).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.097689867019653\n",
      "RSS Mem Usage: cur=246.98 incr=1.78 acc_incr=-110.36 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.79 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.0020393 Vali Loss: 1.3643702\n",
      "Validation loss decreased (inf --> 1.364370).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.1766459941864\n",
      "RSS Mem Usage: cur=247.42 incr=0.44 acc_incr=-109.92 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.79 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.4340047 Vali Loss: 1.3989261\n",
      "Validation loss decreased (inf --> 1.398926).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.06114888191223\n",
      "RSS Mem Usage: cur=247.98 incr=0.56 acc_incr=-109.36 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.80 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.0144039 Vali Loss: 1.2697034\n",
      "Validation loss decreased (inf --> 1.269703).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.105663299560547\n",
      "RSS Mem Usage: cur=245.91 incr=-2.08 acc_incr=-111.44 MB\n",
      "Python Mem Usage: cur=2.81 incr=0.00 acc_incr=2.80 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.0091328 Vali Loss: 1.1723341\n",
      "Validation loss decreased (inf --> 1.172334).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.151984214782715\n",
      "RSS Mem Usage: cur=245.03 incr=-0.88 acc_incr=-112.31 MB\n",
      "Python Mem Usage: cur=2.82 incr=0.01 acc_incr=2.81 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.4392214 Vali Loss: 1.3805577\n",
      "Validation loss decreased (inf --> 1.380558).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.138681888580322\n",
      "RSS Mem Usage: cur=228.20 incr=-16.83 acc_incr=-129.14 MB\n",
      "Python Mem Usage: cur=2.82 incr=0.00 acc_incr=2.81 peak=3.06 MB\n",
      "Epoch: 1 | Train Loss: 0.0278514 Vali Loss: 1.1330386\n",
      "Validation loss decreased (inf --> 1.133039).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.037811756134033\n",
      "RSS Mem Usage: cur=244.39 incr=16.19 acc_incr=-112.95 MB\n",
      "Python Mem Usage: cur=2.79 incr=-0.03 acc_incr=2.78 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.8785372 Vali Loss: 1.2280178\n",
      "Validation loss decreased (inf --> 1.228018).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.10715079307556\n",
      "RSS Mem Usage: cur=223.42 incr=-20.97 acc_incr=-133.92 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.79 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.2395123 Vali Loss: 1.3856226\n",
      "Validation loss decreased (inf --> 1.385623).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.28687882423401\n",
      "RSS Mem Usage: cur=249.45 incr=26.03 acc_incr=-107.89 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.01 acc_incr=2.80 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.0014797 Vali Loss: 1.1509432\n",
      "Validation loss decreased (inf --> 1.150943).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.045337677001953\n",
      "RSS Mem Usage: cur=245.88 incr=-3.58 acc_incr=-111.47 MB\n",
      "Python Mem Usage: cur=2.80 incr=0.00 acc_incr=2.80 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.0000097 Vali Loss: 1.7846276\n",
      "Validation loss decreased (inf --> 1.784628).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.12344789505005\n",
      "RSS Mem Usage: cur=245.66 incr=-0.22 acc_incr=-111.69 MB\n",
      "Python Mem Usage: cur=2.81 incr=0.01 acc_incr=2.80 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.0225470 Vali Loss: 1.7263370\n",
      "Validation loss decreased (inf --> 1.726337).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.162524938583374\n",
      "RSS Mem Usage: cur=245.38 incr=-0.28 acc_incr=-111.97 MB\n",
      "Python Mem Usage: cur=2.82 incr=0.01 acc_incr=2.81 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.0217639 Vali Loss: 1.6434103\n",
      "Validation loss decreased (inf --> 1.643410).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.16023087501526\n",
      "RSS Mem Usage: cur=208.70 incr=-36.67 acc_incr=-148.64 MB\n",
      "Python Mem Usage: cur=2.82 incr=0.01 acc_incr=2.82 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 1.2622241 Vali Loss: 1.5533762\n",
      "Validation loss decreased (inf --> 1.553376).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.104859113693237\n",
      "RSS Mem Usage: cur=248.58 incr=39.88 acc_incr=-108.77 MB\n",
      "Python Mem Usage: cur=2.83 incr=0.01 acc_incr=2.82 peak=3.07 MB\n",
      "Epoch: 1 | Train Loss: 0.1548511 Vali Loss: 1.9105991\n",
      "Validation loss decreased (inf --> 1.910599).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.25303864479065\n",
      "RSS Mem Usage: cur=250.67 incr=2.09 acc_incr=-106.67 MB\n",
      "Python Mem Usage: cur=2.80 incr=-0.03 acc_incr=2.79 peak=3.08 MB\n",
      "Epoch: 1 | Train Loss: 1.4582883 Vali Loss: 1.4707775\n",
      "Validation loss decreased (inf --> 1.470778).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "_train_batch_with_validation: cost time: 19.221045970916748\n",
      "RSS Mem Usage: cur=216.06 incr=-34.61 acc_incr=-141.28 MB\n",
      "Python Mem Usage: cur=2.81 incr=0.01 acc_incr=2.80 peak=3.08 MB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from run import run \n",
    "\n",
    "args_str = \\\n",
    "\"--task_name long_term_forecast \\\n",
    "--is_training 1 \\\n",
    "--model TABE --model_id TABE_v0.2 \\\n",
    "--e_layers 2 --d_layers 1 --factor 3 --enc_in 1 --dec_in 1 --c_out 1 --batch_size 10 \\\n",
    "--seq_len 32 --label_len 32 --pred_len 1 --inverse \\\n",
    "--itr 1 --train_epochs 1 --learning_rate 0.001 --des 'Exp' --loss 'MSE' \\\n",
    "--data TABE --features MS --freq d --root_path ./ --data_path dataset_BTC_r25.csv \"\n",
    "\n",
    "args = args_str.split()\n",
    "\n",
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSCookbook",
   "language": "python",
   "name": "tscookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
